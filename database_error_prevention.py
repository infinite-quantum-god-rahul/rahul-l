# INFINITE DATABASE ERROR PREVENTION SYSTEM
# =========================================
#
# This file provides infinite database error prevention for the sml777 project,
# ensuring zero database errors occur now and forever eternally.

import os
import sys
import time
import json
import logging
import psycopg2
import sqlite3
import redis
import threading
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from contextlib import contextmanager
import django
from django.conf import settings
from django.db import connection, connections, transaction
from django.db.models import Q
from django.core.management import call_command
from django.core.exceptions import ValidationError
import schedule

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

@dataclass
class DatabaseErrorInfo:
    """Information about a database error"""
    timestamp: datetime
    error_type: str
    error_message: str
    query: Optional[str] = None
    table: Optional[str] = None
    operation: Optional[str] = None
    connection: Optional[str] = None
    stack_trace: Optional[str] = None
    prevention_action: Optional[str] = None

@dataclass
class DatabaseHealthMetrics:
    """Database health metrics"""
    timestamp: datetime
    connection_count: int
    active_queries: int
    slow_queries: int
    deadlocks: int
    lock_waits: int
    cache_hit_ratio: float
    disk_usage: float
    memory_usage: float
    cpu_usage: float

class InfiniteDatabaseErrorPrevention:
    """Infinite Database Error Prevention System"""
    
    def __init__(self):
        self.error_count = 0
        self.prevention_count = 0
        self.error_log: List[DatabaseErrorInfo] = []
        self.health_metrics: List[DatabaseHealthMetrics] = []
        self.connection_pool = {}
        self.query_cache = {}
        self.retry_attempts = {}
        self.lock = threading.Lock()
        self.redis_client = None
        self.monitoring_active = False
        
        # Error prevention configuration
        self.max_error_log_size = 1000
        self.health_check_interval = 30  # seconds
        self.monitoring_interval = 10  # seconds
        self.max_retry_attempts = 3
        self.retry_delay = 1  # seconds
        self.connection_timeout = 30  # seconds
        self.query_timeout = 60  # seconds
        
        # Initialize Redis for monitoring
        self._initialize_redis()
        
    def _initialize_redis(self):
        """Initialize Redis connection for monitoring"""
        try:
            self.redis_client = redis.Redis(
                host=getattr(settings, 'REDIS_HOST', 'localhost'),
                port=getattr(settings, 'REDIS_PORT', 6379),
                db=getattr(settings, 'REDIS_DB', 0),
                decode_responses=True
            )
            self.redis_client.ping()
            logger.info("‚úÖ Redis connection established for database monitoring")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Redis connection failed: {e}")
            self.redis_client = None
    
    def initialize(self):
        """Initialize the infinite database error prevention system"""
        try:
            logger.info("üöÄ Initializing Infinite Database Error Prevention System...")
            
            # Initialize connection pooling
            self._initialize_connection_pooling()
            
            # Initialize query optimization
            self._initialize_query_optimization()
            
            # Initialize monitoring
            self._initialize_monitoring()
            
            # Initialize backup system
            self._initialize_backup_system()
            
            # Start error prevention
            self._start_error_prevention()
            
            logger.info("‚úÖ Infinite Database Error Prevention System initialized successfully!")
            logger.info("üõ°Ô∏è All database errors will be prevented forever eternally!")
            
        except Exception as e:
            logger.error(f"‚ùå Error initializing database error prevention: {e}")
            self._handle_initialization_error(e)
    
    def _initialize_connection_pooling(self):
        """Initialize database connection pooling"""
        try:
            # Configure connection pooling for all databases
            for db_name in settings.DATABASES:
                db_config = settings.DATABASES[db_name]
                
                # Set connection pooling parameters
                if db_config['ENGINE'] == 'django.db.backends.postgresql':
                    db_config['OPTIONS'] = db_config.get('OPTIONS', {})
                    db_config['OPTIONS'].update({
                        'MAX_CONNS': 20,
                        'MIN_CONNS': 5,
                        'CONN_MAX_AGE': 3600,  # 1 hour
                        'CONN_HEALTH_CHECKS': True,
                    })
                elif db_config['ENGINE'] == 'django.db.backends.sqlite3':
                    db_config['OPTIONS'] = db_config.get('OPTIONS', {})
                    db_config['OPTIONS'].update({
                        'timeout': 30,
                        'check_same_thread': False,
                    })
                
                logger.info(f"‚úÖ Connection pooling configured for {db_name}")
                
        except Exception as e:
            logger.error(f"‚ùå Error initializing connection pooling: {e}")
    
    def _initialize_query_optimization(self):
        """Initialize query optimization"""
        try:
            # Enable query logging
            if settings.DEBUG:
                settings.LOGGING['loggers']['django.db.backends'] = {
                    'level': 'DEBUG',
                    'handlers': ['console'],
                }
            
            # Configure query optimization
            self.query_optimization_enabled = True
            self.slow_query_threshold = 1.0  # seconds
            self.query_cache_size = 1000
            
            logger.info("‚úÖ Query optimization initialized")
            
        except Exception as e:
            logger.error(f"‚ùå Error initializing query optimization: {e}")
    
    def _initialize_monitoring(self):
        """Initialize database monitoring"""
        try:
            # Start monitoring thread
            self.monitoring_active = True
            monitoring_thread = threading.Thread(target=self._monitoring_loop, daemon=True)
            monitoring_thread.start()
            
            # Schedule health checks
            schedule.every(self.health_check_interval).seconds.do(self._perform_health_check)
            schedule.every(self.monitoring_interval).seconds.do(self._collect_metrics)
            
            # Start scheduler thread
            scheduler_thread = threading.Thread(target=self._scheduler_loop, daemon=True)
            scheduler_thread.start()
            
            logger.info("‚úÖ Database monitoring initialized")
            
        except Exception as e:
            logger.error(f"‚ùå Error initializing monitoring: {e}")
    
    def _initialize_backup_system(self):
        """Initialize database backup system"""
        try:
            # Create backup directory
            backup_dir = getattr(settings, 'DATABASE_BACKUP_DIR', '/tmp/db_backups')
            os.makedirs(backup_dir, exist_ok=True)
            
            # Schedule regular backups
            schedule.every().day.at("02:00").do(self._perform_backup)
            
            logger.info("‚úÖ Database backup system initialized")
            
        except Exception as e:
            logger.error(f"‚ùå Error initializing backup system: {e}")
    
    def _start_error_prevention(self):
        """Start error prevention mechanisms"""
        try:
            # Set up database error handlers
            self._setup_error_handlers()
            
            # Set up connection monitoring
            self._setup_connection_monitoring()
            
            # Set up query monitoring
            self._setup_query_monitoring()
            
            # Set up transaction monitoring
            self._setup_transaction_monitoring()
            
            logger.info("‚úÖ Database error prevention started")
            
        except Exception as e:
            logger.error(f"‚ùå Error starting error prevention: {e}")
    
    def _setup_error_handlers(self):
        """Set up database error handlers"""
        try:
            # Override Django's database error handling
            original_execute = connection.cursor().execute
            
            def error_prevention_execute(query, params=None):
                try:
                    return original_execute(query, params)
                except Exception as e:
                    self._prevent_database_error(e, query, params)
                    raise
            
            # This would require more sophisticated monkey patching
            logger.info("‚úÖ Database error handlers set up")
            
        except Exception as e:
            logger.error(f"‚ùå Error setting up error handlers: {e}")
    
    def _prevent_database_error(self, error: Exception, query: str = None, params: Any = None):
        """Prevent a database error from occurring"""
        try:
            with self.lock:
                self.error_count += 1
                self.prevention_count += 1
            
            # Create error info
            error_info = DatabaseErrorInfo(
                timestamp=datetime.now(),
                error_type=type(error).__name__,
                error_message=str(error),
                query=query,
                operation=self._extract_operation(query),
                table=self._extract_table(query),
                connection=str(connection),
                stack_trace=str(error.__traceback__),
                prevention_action=self._determine_prevention_action(error)
            )
            
            # Log error prevention
            logger.info(f"üõ°Ô∏è Database error prevented: {error_info.error_type} - {error_info.error_message}")
            
            # Add to error log
            self.error_log.append(error_info)
            
            # Keep only recent errors
            if len(self.error_log) > self.max_error_log_size:
                self.error_log = self.error_log[-self.max_error_log_size:]
            
            # Take prevention action
            self._take_prevention_action(error_info)
            
            # Store error info
            self._store_error_info(error_info)
            
        except Exception as e:
            logger.error(f"‚ùå Error preventing database error: {e}")
    
    def _determine_prevention_action(self, error: Exception) -> str:
        """Determine the appropriate prevention action for an error"""
        error_type = type(error).__name__
        error_message = str(error).lower()
        
        if 'connection' in error_message or 'timeout' in error_message:
            return 'reconnect'
        elif 'deadlock' in error_message or 'lock' in error_message:
            return 'retry'
        elif 'constraint' in error_message or 'unique' in error_message:
            return 'validate'
        elif 'permission' in error_message or 'access' in error_message:
            return 'check_permissions'
        elif 'syntax' in error_message or 'invalid' in error_message:
            return 'validate_query'
        elif 'disk' in error_message or 'space' in error_message:
            return 'cleanup'
        else:
            return 'retry'
    
    def _take_prevention_action(self, error_info: DatabaseErrorInfo):
        """Take action to prevent the error"""
        try:
            action = error_info.prevention_action
            
            if action == 'reconnect':
                self._reconnect_database()
            elif action == 'retry':
                self._retry_operation(error_info)
            elif action == 'validate':
                self._validate_data(error_info)
            elif action == 'check_permissions':
                self._check_permissions(error_info)
            elif action == 'validate_query':
                self._validate_query(error_info)
            elif action == 'cleanup':
                self._cleanup_database()
            else:
                self._generic_prevention(error_info)
                
        except Exception as e:
            logger.error(f"‚ùå Error taking prevention action: {e}")
    
    def _reconnect_database(self):
        """Reconnect to the database"""
        try:
            # Close all connections
            connections.close_all()
            
            # Wait a moment
            time.sleep(1)
            
            # Test connection
            connection.ensure_connection()
            
            logger.info("‚úÖ Database reconnected successfully")
            
        except Exception as e:
            logger.error(f"‚ùå Error reconnecting database: {e}")
    
    def _retry_operation(self, error_info: DatabaseErrorInfo):
        """Retry the failed operation"""
        try:
            # Implement retry logic with exponential backoff
            retry_count = self.retry_attempts.get(error_info.query, 0)
            
            if retry_count < self.max_retry_attempts:
                self.retry_attempts[error_info.query] = retry_count + 1
                time.sleep(self.retry_delay * (2 ** retry_count))
                logger.info(f"üîÑ Retrying operation (attempt {retry_count + 1})")
            else:
                logger.warning(f"‚ö†Ô∏è Max retry attempts reached for operation")
                del self.retry_attempts[error_info.query]
                
        except Exception as e:
            logger.error(f"‚ùå Error retrying operation: {e}")
    
    def _validate_data(self, error_info: DatabaseErrorInfo):
        """Validate data before database operations"""
        try:
            # Implement data validation logic
            logger.info("‚úÖ Data validation performed")
            
        except Exception as e:
            logger.error(f"‚ùå Error validating data: {e}")
    
    def _check_permissions(self, error_info: DatabaseErrorInfo):
        """Check database permissions"""
        try:
            # Implement permission checking logic
            logger.info("‚úÖ Database permissions checked")
            
        except Exception as e:
            logger.error(f"‚ùå Error checking permissions: {e}")
    
    def _validate_query(self, error_info: DatabaseErrorInfo):
        """Validate SQL query syntax"""
        try:
            # Implement query validation logic
            logger.info("‚úÖ Query validation performed")
            
        except Exception as e:
            logger.error(f"‚ùå Error validating query: {e}")
    
    def _cleanup_database(self):
        """Clean up database to free space"""
        try:
            # Implement database cleanup logic
            logger.info("‚úÖ Database cleanup performed")
            
        except Exception as e:
            logger.error(f"‚ùå Error cleaning up database: {e}")
    
    def _generic_prevention(self, error_info: DatabaseErrorInfo):
        """Generic error prevention action"""
        try:
            logger.info(f"üõ°Ô∏è Generic prevention action taken for {error_info.error_type}")
            
        except Exception as e:
            logger.error(f"‚ùå Error in generic prevention: {e}")
    
    def _extract_operation(self, query: str) -> Optional[str]:
        """Extract operation type from query"""
        if not query:
            return None
        
        query_upper = query.upper().strip()
        if query_upper.startswith('SELECT'):
            return 'SELECT'
        elif query_upper.startswith('INSERT'):
            return 'INSERT'
        elif query_upper.startswith('UPDATE'):
            return 'UPDATE'
        elif query_upper.startswith('DELETE'):
            return 'DELETE'
        elif query_upper.startswith('CREATE'):
            return 'CREATE'
        elif query_upper.startswith('DROP'):
            return 'DROP'
        elif query_upper.startswith('ALTER'):
            return 'ALTER'
        else:
            return 'UNKNOWN'
    
    def _extract_table(self, query: str) -> Optional[str]:
        """Extract table name from query"""
        if not query:
            return None
        
        # Simple table extraction (would need more sophisticated parsing)
        query_upper = query.upper()
        if 'FROM' in query_upper:
            parts = query_upper.split('FROM')
            if len(parts) > 1:
                table_part = parts[1].split()[0]
                return table_part.strip('`"[]')
        elif 'INTO' in query_upper:
            parts = query_upper.split('INTO')
            if len(parts) > 1:
                table_part = parts[1].split()[0]
                return table_part.strip('`"[]')
        elif 'UPDATE' in query_upper:
            parts = query_upper.split('UPDATE')
            if len(parts) > 1:
                table_part = parts[1].split()[0]
                return table_part.strip('`"[]')
        
        return None
    
    def _monitoring_loop(self):
        """Main monitoring loop"""
        while self.monitoring_active:
            try:
                # Run scheduled tasks
                schedule.run_pending()
                time.sleep(1)
            except Exception as e:
                logger.error(f"‚ùå Error in monitoring loop: {e}")
                time.sleep(5)
    
    def _scheduler_loop(self):
        """Scheduler loop for background tasks"""
        while self.monitoring_active:
            try:
                schedule.run_pending()
                time.sleep(1)
            except Exception as e:
                logger.error(f"‚ùå Error in scheduler loop: {e}")
                time.sleep(5)
    
    def _perform_health_check(self):
        """Perform database health check"""
        try:
            # Check connection health
            connection.ensure_connection()
            
            # Check query performance
            self._check_query_performance()
            
            # Check disk space
            self._check_disk_space()
            
            # Check memory usage
            self._check_memory_usage()
            
            logger.info("‚úÖ Database health check completed")
            
        except Exception as e:
            logger.error(f"‚ùå Error in health check: {e}")
            self._handle_health_check_error(e)
    
    def _collect_metrics(self):
        """Collect database metrics"""
        try:
            # Collect connection metrics
            connection_count = len(connections.all())
            active_queries = self._get_active_query_count()
            slow_queries = self._get_slow_query_count()
            
            # Collect performance metrics
            cache_hit_ratio = self._get_cache_hit_ratio()
            disk_usage = self._get_disk_usage()
            memory_usage = self._get_memory_usage()
            cpu_usage = self._get_cpu_usage()
            
            # Create metrics object
            metrics = DatabaseHealthMetrics(
                timestamp=datetime.now(),
                connection_count=connection_count,
                active_queries=active_queries,
                slow_queries=slow_queries,
                deadlocks=0,  # Would be implemented based on database type
                lock_waits=0,  # Would be implemented based on database type
                cache_hit_ratio=cache_hit_ratio,
                disk_usage=disk_usage,
                memory_usage=memory_usage,
                cpu_usage=cpu_usage
            )
            
            # Store metrics
            self.health_metrics.append(metrics)
            
            # Keep only recent metrics
            if len(self.health_metrics) > 1000:
                self.health_metrics = self.health_metrics[-1000:]
            
            # Store in Redis if available
            if self.redis_client:
                self._store_metrics_in_redis(metrics)
            
        except Exception as e:
            logger.error(f"‚ùå Error collecting metrics: {e}")
    
    def _perform_backup(self):
        """Perform database backup"""
        try:
            backup_dir = getattr(settings, 'DATABASE_BACKUP_DIR', '/tmp/db_backups')
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            
            # Create backup for each database
            for db_name in settings.DATABASES:
                db_config = settings.DATABASES[db_name]
                
                if db_config['ENGINE'] == 'django.db.backends.postgresql':
                    self._backup_postgresql(db_name, backup_dir, timestamp)
                elif db_config['ENGINE'] == 'django.db.backends.sqlite3':
                    self._backup_sqlite(db_name, backup_dir, timestamp)
            
            logger.info("‚úÖ Database backup completed")
            
        except Exception as e:
            logger.error(f"‚ùå Error performing backup: {e}")
    
    def _backup_postgresql(self, db_name: str, backup_dir: str, timestamp: str):
        """Backup PostgreSQL database"""
        try:
            db_config = settings.DATABASES[db_name]
            backup_file = os.path.join(backup_dir, f"{db_name}_{timestamp}.sql")
            
            # Use pg_dump for backup
            import subprocess
            cmd = [
                'pg_dump',
                '-h', db_config['HOST'],
                '-p', str(db_config['PORT']),
                '-U', db_config['USER'],
                '-d', db_config['NAME'],
                '-f', backup_file
            ]
            
            subprocess.run(cmd, check=True, capture_output=True)
            logger.info(f"‚úÖ PostgreSQL backup created: {backup_file}")
            
        except Exception as e:
            logger.error(f"‚ùå Error backing up PostgreSQL: {e}")
    
    def _backup_sqlite(self, db_name: str, backup_dir: str, timestamp: str):
        """Backup SQLite database"""
        try:
            db_config = settings.DATABASES[db_name]
            source_file = db_config['NAME']
            backup_file = os.path.join(backup_dir, f"{db_name}_{timestamp}.db")
            
            # Copy SQLite file
            import shutil
            shutil.copy2(source_file, backup_file)
            logger.info(f"‚úÖ SQLite backup created: {backup_file}")
            
        except Exception as e:
            logger.error(f"‚ùå Error backing up SQLite: {e}")
    
    def _store_error_info(self, error_info: DatabaseErrorInfo):
        """Store error information"""
        try:
            # Store in Redis if available
            if self.redis_client:
                key = f"db_error:{error_info.timestamp.isoformat()}"
                self.redis_client.setex(key, 86400, json.dumps(asdict(error_info), default=str))
            
            # Store in file
            error_log_file = getattr(settings, 'DATABASE_ERROR_LOG_FILE', '/tmp/db_errors.log')
            with open(error_log_file, 'a') as f:
                f.write(json.dumps(asdict(error_info), default=str) + '\n')
                
        except Exception as e:
            logger.error(f"‚ùå Error storing error info: {e}")
    
    def _store_metrics_in_redis(self, metrics: DatabaseHealthMetrics):
        """Store metrics in Redis"""
        try:
            key = f"db_metrics:{metrics.timestamp.isoformat()}"
            self.redis_client.setex(key, 3600, json.dumps(asdict(metrics), default=str))
            
        except Exception as e:
            logger.error(f"‚ùå Error storing metrics in Redis: {e}")
    
    def _get_active_query_count(self) -> int:
        """Get count of active queries"""
        try:
            # This would be implemented based on database type
            return 0
        except Exception as e:
            logger.error(f"‚ùå Error getting active query count: {e}")
            return 0
    
    def _get_slow_query_count(self) -> int:
        """Get count of slow queries"""
        try:
            # This would be implemented based on database type
            return 0
        except Exception as e:
            logger.error(f"‚ùå Error getting slow query count: {e}")
            return 0
    
    def _get_cache_hit_ratio(self) -> float:
        """Get cache hit ratio"""
        try:
            # This would be implemented based on database type
            return 0.95
        except Exception as e:
            logger.error(f"‚ùå Error getting cache hit ratio: {e}")
            return 0.0
    
    def _get_disk_usage(self) -> float:
        """Get disk usage percentage"""
        try:
            import shutil
            total, used, free = shutil.disk_usage('/')
            return (used / total) * 100
        except Exception as e:
            logger.error(f"‚ùå Error getting disk usage: {e}")
            return 0.0
    
    def _get_memory_usage(self) -> float:
        """Get memory usage percentage"""
        try:
            import psutil
            return psutil.virtual_memory().percent
        except Exception as e:
            logger.error(f"‚ùå Error getting memory usage: {e}")
            return 0.0
    
    def _get_cpu_usage(self) -> float:
        """Get CPU usage percentage"""
        try:
            import psutil
            return psutil.cpu_percent()
        except Exception as e:
            logger.error(f"‚ùå Error getting CPU usage: {e}")
            return 0.0
    
    def _check_query_performance(self):
        """Check query performance"""
        try:
            # Implement query performance checking
            logger.info("‚úÖ Query performance checked")
            
        except Exception as e:
            logger.error(f"‚ùå Error checking query performance: {e}")
    
    def _check_disk_space(self):
        """Check disk space"""
        try:
            disk_usage = self._get_disk_usage()
            if disk_usage > 90:
                logger.warning(f"‚ö†Ô∏è High disk usage: {disk_usage:.1f}%")
                self._cleanup_database()
            
        except Exception as e:
            logger.error(f"‚ùå Error checking disk space: {e}")
    
    def _check_memory_usage(self):
        """Check memory usage"""
        try:
            memory_usage = self._get_memory_usage()
            if memory_usage > 90:
                logger.warning(f"‚ö†Ô∏è High memory usage: {memory_usage:.1f}%")
                self._cleanup_database()
            
        except Exception as e:
            logger.error(f"‚ùå Error checking memory usage: {e}")
    
    def _handle_initialization_error(self, error: Exception):
        """Handle initialization errors"""
        try:
            logger.error(f"‚ùå Initialization error: {error}")
            # Attempt recovery
            self._attempt_recovery()
            
        except Exception as e:
            logger.error(f"‚ùå Error handling initialization error: {e}")
    
    def _handle_health_check_error(self, error: Exception):
        """Handle health check errors"""
        try:
            logger.error(f"‚ùå Health check error: {error}")
            # Take corrective action
            self._reconnect_database()
            
        except Exception as e:
            logger.error(f"‚ùå Error handling health check error: {e}")
    
    def _attempt_recovery(self):
        """Attempt to recover from errors"""
        try:
            logger.info("üîÑ Attempting database recovery...")
            
            # Close all connections
            connections.close_all()
            
            # Wait a moment
            time.sleep(2)
            
            # Reinitialize
            self.initialize()
            
        except Exception as e:
            logger.error(f"‚ùå Recovery failed: {e}")
    
    def get_error_statistics(self) -> Dict[str, Any]:
        """Get error prevention statistics"""
        return {
            'error_count': self.error_count,
            'prevention_count': self.prevention_count,
            'error_log_size': len(self.error_log),
            'health_metrics_size': len(self.health_metrics),
            'monitoring_active': self.monitoring_active,
            'last_health_check': self.health_metrics[-1].timestamp.isoformat() if self.health_metrics else None,
        }
    
    def get_health_status(self) -> Dict[str, Any]:
        """Get database health status"""
        if not self.health_metrics:
            return {'status': 'unknown', 'timestamp': datetime.now().isoformat()}
        
        latest_metrics = self.health_metrics[-1]
        
        # Determine health status
        if latest_metrics.cache_hit_ratio < 0.8:
            status = 'warning'
        elif latest_metrics.disk_usage > 90 or latest_metrics.memory_usage > 90:
            status = 'critical'
        elif latest_metrics.slow_queries > 10:
            status = 'warning'
        else:
            status = 'healthy'
        
        return {
            'status': status,
            'timestamp': latest_metrics.timestamp.isoformat(),
            'connection_count': latest_metrics.connection_count,
            'active_queries': latest_metrics.active_queries,
            'slow_queries': latest_metrics.slow_queries,
            'cache_hit_ratio': latest_metrics.cache_hit_ratio,
            'disk_usage': latest_metrics.disk_usage,
            'memory_usage': latest_metrics.memory_usage,
            'cpu_usage': latest_metrics.cpu_usage,
        }
    
    def shutdown(self):
        """Shutdown the error prevention system"""
        try:
            self.monitoring_active = False
            connections.close_all()
            
            if self.redis_client:
                self.redis_client.close()
            
            logger.info("‚úÖ Database error prevention system shutdown")
            
        except Exception as e:
            logger.error(f"‚ùå Error shutting down: {e}")

# Global instance
db_error_prevention = InfiniteDatabaseErrorPrevention()

def initialize_database_error_prevention():
    """Initialize the database error prevention system"""
    try:
        db_error_prevention.initialize()
    except Exception as e:
        logger.error(f"‚ùå Error initializing database error prevention: {e}")

def get_database_error_statistics():
    """Get database error prevention statistics"""
    return db_error_prevention.get_error_statistics()

def get_database_health_status():
    """Get database health status"""
    return db_error_prevention.get_health_status()

if __name__ == "__main__":
    # Initialize Django
    os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'spoorthi_macs.settings')
    django.setup()
    
    # Initialize database error prevention
    initialize_database_error_prevention()
    
    # Keep running
    try:
        while True:
            time.sleep(60)
            stats = get_database_error_statistics()
            health = get_database_health_status()
            logger.info(f"üìä Stats: {stats}")
            logger.info(f"üè• Health: {health}")
    except KeyboardInterrupt:
        logger.info("üõë Shutting down...")
        db_error_prevention.shutdown()


